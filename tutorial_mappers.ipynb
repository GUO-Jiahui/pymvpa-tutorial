{
 "metadata": {
  "name": "",
  "signature": "sha256:fd3758d5979ae952ce2780dface0aecd9c2b05aab11ba6f3f8e658741bd98e0a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Getting data in shape"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "In the tutorial part *chap_tutorial_datasets* we have discovered a magic\n",
      "ingredient of datasets: a [Mapper](http://pymvpa.org/generated/mvpa2.mappers.base.Mapper.html#mvpa2-mappers-base-mapper). Mappers are\n",
      "probably the most powerful concept in PyMVPA, and there is little one would do\n",
      "without them.\n",
      "\n",
      "In general, a mapper is an algorithm that transforms data.\n",
      "This transformation can be as simple as selecting a subset of data, or as\n",
      "complex as a multi-stage preprocessing pipeline. Some transformations are\n",
      "reversible, others are not. Some are simple one-step computations, others\n",
      "are iterative algorithms that have to be trained on data before they can be\n",
      "used. In PyMVPA, all these transformations are [mappers](http://pymvpa.org/generated/mvpa2.mappers.html#mvpa2-mappers)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "*Note*\n",
      "\n",
      "\n",
      "\n",
      "If you are an \n",
      "[MDP](http://mdp-toolkit.sourceforge.net/)-user you probably have realized the similarity of MDP's\n",
      "nodes and PyMVPA's mappers.\n",
      "- - -\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Let's create a dummy dataset (5 samples, 12 features). This time we will use a\n",
      "new method to create the dataset, the `dataset_wizard`. Here it is, fully\n",
      "equivalent to a regular constructor call (i.e.\n",
      "[Dataset](http://pymvpa.org/generated/mvpa2.datasets.base.Dataset.html#mvpa2-datasets-base-dataset)), but we will shortly see some nice convenience\n",
      "aspects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mvpa2.tutorial_suite import *\n",
      "ds = dataset_wizard(np.ones((5, 12)))\n",
      "ds.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "(5, 12)"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Some datasets (such as the ones [fmri_dataset()](http://pymvpa.org/generated/mvpa2.datasets.mri.fmri_dataset.html#mvpa2-datasets-mri-fmri-dataset) with a\n",
      "mask) contain mappers as a [dataset attribute](http://pymvpa.org/glossary.html#term-dataset-attribute) `.a.mapper`.\n",
      "However, not every dataset actually has\n",
      "a mapper. For example, the simple one we have just created doesn't have any:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'mapper' in ds.a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Now let's look at a very similar dataset that only differs in a tiny but\n",
      "a very important detail:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds = dataset_wizard(np.ones((5, 4, 3)))\n",
      "ds.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "(5, 12)"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'mapper' in ds.a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ds.a.mapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<FlattenMapper>\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "We see that the resulting dataset looks identical to the one above, but this\n",
      "time it got created from a 3D samples array (i.e. five samples, where each is a\n",
      "4x3 matrix). Somehow this 3D array got transformed into a 2D samples array in\n",
      "the dataset. This magic behavior is unveiled by observing that the dataset's\n",
      "mapper is a [FlattenMapper](http://pymvpa.org/generated/mvpa2.mappers.flatten.FlattenMapper.html#mvpa2-mappers-flatten-flattenmapper).\n",
      "\n",
      "The purpose of this mapper is precisely what we have just observed: reshaping\n",
      "data arrays into 2D. It does it by preserving the first axis (in PyMVPA\n",
      "datasets this is the axis that separates the samples) and concatenates all\n",
      "other axis into the second one.\n",
      "\n",
      "Since mappers represent particular transformations they can also be seen as a\n",
      "protocol of what has been done. If we look at the dataset, we know that it had\n",
      "been flattened on the way from its origin to a samples array in a dataset. This\n",
      "feature can become really useful, if the processing become more complex. Let's\n",
      "look at a possible next step -- selecting a subset of interesting features:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "myfavs = [1, 2, 8, 10]\n",
      "subds = ds[:, myfavs]\n",
      "subds.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "(5, 4)"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'mapper' in subds.a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print subds.a.mapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Chain: <Flatten>-<StaticFeatureSelection>>\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Now the situation has changed: *two* new mappers appeared in the dataset -- a\n",
      "[ChainMapper](http://pymvpa.org/generated/mvpa2.mappers.base.ChainMapper.html#mvpa2-mappers-base-chainmapper) and a\n",
      "[StaticFeatureSelection](http://pymvpa.org/generated/mvpa2.featsel.base.StaticFeatureSelection.html#mvpa2-featsel-base-staticfeatureselection).  The latter describes (and\n",
      "actually performs) the slicing operation we just made, while the former\n",
      "encapsulates the two mappers into a processing pipeline.  We can see that the\n",
      "mapper chain represents the processing history of the dataset like a breadcrumb\n",
      "track.\n",
      "\n",
      "As it has been mentioned, mappers not only can transform a single dataset, but\n",
      "can be fed with other data (as long as it is compatible with the mapper)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fwdtest = np.arange(12).reshape(4,3)\n",
      "print fwdtest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0  1  2]\n",
        " [ 3  4  5]\n",
        " [ 6  7  8]\n",
        " [ 9 10 11]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fmapped = subds.a.mapper.forward1(fwdtest)\n",
      "fmapped.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "(4,)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fmapped"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1  2  8 10]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Although `subds` has less features than our input data, forward mapping\n",
      "applies the same transformation that had been done to the dataset itself also\n",
      "to our test 4x3 array. The procedure yields a feature vector of the same shape\n",
      "as the one in `subds`. By looking at the forward-mapped data, we can verify\n",
      "that the correct features have been chosen."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load real data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "We have pretty much all the pieces to start a first analysis.  We know how to\n",
      "load fMRI data from time series images, we know how to add and access\n",
      "attributes in a dataset, we know how to slice datasets, and we know that we can\n",
      "manipulate datasets with mappers.\n",
      "\n",
      "Now our goal is to combine all these little pieces into the code that produces\n",
      "a dataset like the one used in the seminal work by \n",
      "\n",
      "> *Haxby et al. (2001)* -- a study were participants passively watched gray scale images of\n",
      "eight object categories in a block-design experiment. From the raw BOLD time\n",
      "series, of which we have the full 12 recording runs of the first subject, they\n",
      "computed:A *pattern of activation* for each stimulus category in each half of the\n",
      "data (split by odd vs. even runs; i.e. 16 samples), including the\n",
      "associated [sample attribute](http://pymvpa.org/glossary.html#term-sample-attribute)s that are necessary to perform a\n",
      "cross-validated classification analysis of the data.\n",
      "\n",
      "We have already seen how fMRI data can be loaded from NIfTI images, but this\n",
      "time we need more than just the EPI images. For a classification analysis we\n",
      "also need to associate each sample with a corresponding experimental condition,\n",
      "i.e. a class label, also sometimes called [target](http://pymvpa.org/glossary.html#term-target) value.  Moreover, for\n",
      "a cross-validation procedure we also need to partition the full dataset into,\n",
      "presumably, independent [chunk](http://pymvpa.org/glossary.html#term-chunk)s. Independence is critical to achieve\n",
      "an unbiased estimate of the generalization performance of a classifier, i.e.\n",
      "its accuracy in predicting the correct class label for new data, unseen during\n",
      "training. So, where do we get this information from?\n",
      "\n",
      "Both, target values and chunks are defined by the design of the experiment.\n",
      "In the simplest case the target value for an fMRI volume sample is the\n",
      "experiment condition that has been present/active while the volume has been\n",
      "acquired. However, there are more complicated scenarios which we will look\n",
      "at later on. Chunks of independent data correspond to what fMRI volumes are\n",
      "assumed to be independent. The properties of the MRI acquisition process\n",
      "cause subsequently acquired volumes to be *very* similar, hence they cannot\n",
      "be considered independent. Ideally, the experiment is split into several\n",
      "acquisition sessions, where the sessions define the corresponding data\n",
      "chunks.\n",
      "\n",
      "There are many ways to import this information into PyMVPA. The most simple\n",
      "one is to create a two-column text file that has the target value in the\n",
      "first column, and the chunk identifier in the second, with one line per\n",
      "volume in the NIfTI image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_path = os.path.join(tutorial_data_path, 'haxby2001')\n",
      "attr_fname = os.path.join(data_path, 'sub001',\n",
      "                          'BOLD', 'task001_run001', 'attributes.txt')\n",
      "attr = SampleAttributes(attr_fname)\n",
      "print attr.keys()\n",
      "len(attr.targets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['chunks', 'targets']\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "121"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.unique(attr.targets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['bottle' 'cat' 'chair' 'face' 'house' 'rest' 'scissors' 'scrambledpix'\n",
        " 'shoe']\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(attr.chunks)\n",
      "print attr.chunks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.unique(attr.chunks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "[SampleAttributes](http://pymvpa.org/generated/mvpa2.misc.io.base.SampleAttributes.html#mvpa2-misc-io-base-sampleattributes) allows us to load this type of\n",
      "file, and access its content. We got 121 labels and chunk values, one for each\n",
      "volume. Moreover, we see that there are nine different conditions and all\n",
      "samples are associated with the same chunk. The attributes file for a different\n",
      "scan/run would increment the chunk value.\n",
      "\n",
      "Now we can load the fMRI data, as we have done before -- only loading voxels\n",
      "corresponding to a mask of ventral temporal cortex, and assign the samples\n",
      "attributes to the dataset. [fmri_dataset()](http://pymvpa.org/generated/mvpa2.datasets.mri.fmri_dataset.html#mvpa2-datasets-mri-fmri-dataset) allows us to\n",
      "pass them directly:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bold_fname = os.path.join(data_path,\n",
      "                          'sub001', 'BOLD', 'task001_run001', 'bold.nii.gz')\n",
      "mask_fname = os.path.join(tutorial_data_path, 'haxby2001',\n",
      "                          'sub001', 'masks', 'orig', 'vt.nii.gz')\n",
      "fds = fmri_dataset(samples=bold_fname,\n",
      "                   targets=attr.targets, chunks=attr.chunks,\n",
      "                   mask=mask_fname)\n",
      "fds.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "(121, 577)"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fds.sa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<SampleAttributesCollection: chunks,targets,time_coords,time_indices>\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "We got the dataset that we already know from the last part, but this time\n",
      "is also has information about chunks and targets."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "More structure, less duplication of work"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Although one could craft individual attribute files for each fMRI scan, doing\n",
      "so would be suboptimal. Typically, stimulation is not synchronous with\n",
      "fMRI volume sampling rate, hence timing information would be lost. Moreover,\n",
      "information on stimulation, or experiment design in general, is most likely\n",
      "available already in different form or shape.\n",
      "\n",
      "To ease working with a broad range of datasets, PyMVPA comes with dedicated\n",
      "support for datasets following the specifications used by the [openfmri.org](http://www.openfmri.org)\n",
      "data-sharing platform. These are simple guidelines for file name conventions\n",
      "and design specification that can be easily adopted for your own data."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Exercise**\n",
      "\n",
      "\n",
      "\n",
      "The tutorial data you are working with is following the openfmri.org\n",
      "scheme. Open the dataset folder and inspect the structure and content\n",
      "of the files with meta data. Notice, that it is possible to run a standard\n",
      "analysis using, for example, FSL's FEAT directly on this data in unmodified\n",
      "form."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you can use this cell for this exercise"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "\n",
      "\n",
      "Accessing such a dataset is done via a handler that simply needs to know\n",
      "where the dataset is stored on disk. This handler offers convenient access\n",
      "to basic information, such as the number of subjects, task descriptions,\n",
      "and other properties."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dhandle = OpenFMRIDataset(data_path)\n",
      "dhandle.get_subj_ids()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "[1]"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dhandle.get_task_descriptions()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "{1: 'object viewing'}"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "More importantly, it supports access to information on experiment design:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = 1\n",
      "subj = 1\n",
      "run = 1\n",
      "events = dhandle.get_bold_run_model(model, subj, run)\n",
      "for ev in events[:2]:\n",
      "    print ev"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'task': 1, 'run': 1, 'onset_idx': 0, 'conset_idx': 0, 'onset': 15.0, 'intensity': 1, 'duration': 22.5, 'condition': 'scissors'}\n",
        "{'task': 1, 'run': 1, 'onset_idx': 1, 'conset_idx': 0, 'onset': 52.5, 'intensity': 1, 'duration': 22.5, 'condition': 'face'}\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "As you can see, the stimulus design information is available in a list of\n",
      "standard Python dictionaries for each event. This includes onset and duration\n",
      "of the stimulation, as well as literal condition labels, and task descriptions.\n",
      "\n",
      "With a utility function it is straightforward to convert such an event list\n",
      "into a sample attribute array like the one we have loaded from a file before.\n",
      "`events2sample_attr()` uses the sample acquisition time information stored in\n",
      "the dataset's `time_coords` sample attribute to match stimulation events to\n",
      "data samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "targets = events2sample_attr(events, fds.sa.time_coords,\n",
      "                             noinfolabel='rest', onset_shift=0.0)\n",
      "print np.unique([attr.targets[i] == targets[i] for i in range(len(targets))])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ True]\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print np.unique(attr.targets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['bottle' 'cat' 'chair' 'face' 'house' 'rest' 'scissors' 'scrambledpix'\n",
        " 'shoe']\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " print len(fds), len(targets)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "121 121\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Note, that the conversion of stimulation events to attribute arrays is a rather\n",
      "crude way of labeling fMRI data that only works well with block-design-like\n",
      "experiments. We will see other approaches later in this tutorial.\n",
      "\n",
      "In addition to experiment design information, the dataset handler also offers\n",
      "convenient access to the actual BOLD fMRI data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "task = 1\n",
      "fds = dhandle.get_bold_run_dataset(subj, task, run, mask=mask_fname)\n",
      "print fds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Dataset: 121x577@int16, <sa: run,subj,task,time_coords,time_indices>, <fa: voxel_indices>, <a: imgaffine,imghdr,imgtype,mapper,voxel_dim,voxel_eldim>>\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "The method `get_bold_run_dataset()` works the same way as `fmri_dataset()`,\n",
      "which we have seen before, and also supports the same arguments. However,\n",
      "instead of giving a custom filename, BOLD data is identified by subject, task,\n",
      "and acquisition run IDs."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Multi-session data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Many fMRI experiments involve multiple runs. Loading such data is best done\n",
      "in a loop. The following code snippet loads all available runs for the object\n",
      "viewing task from our example subject in the dataset."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "task = 1   # object viewing task\n",
      "model = 1  # image stimulus category model\n",
      "subj = 1\n",
      "run_datasets = []\n",
      "for run_id in dhandle.get_task_bold_run_ids(task)[subj]:\n",
      "    # load design info for this run\n",
      "    run_events = dhandle.get_bold_run_model(model, subj, run_id)\n",
      "    # load BOLD data for this run (with masking); add 0-based chunk ID\n",
      "    run_ds = dhandle.get_bold_run_dataset(subj, task, run_id,\n",
      "                                          chunks=run_id -1,\n",
      "                                          mask=mask_fname)\n",
      "    # convert event info into a sample attribute and assign as 'targets'\n",
      "    run_ds.sa['targets'] = events2sample_attr(\n",
      "                run_events, run_ds.sa.time_coords, noinfolabel='rest')\n",
      "    # additional time series preprocessing can go here\n",
      "    run_datasets.append(run_ds)\n",
      "fds = vstack(run_datasets, a=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Now it is a good time to obtain a [summary()](http://pymvpa.org/generated/mvpa2.datasets.miscfx.summary.html#mvpa2-datasets-miscfx-summary) overview\n",
      "of the dataset: basic statistics, balance in number of samples among targets\n",
      "per chunk, etc.:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fds.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Dataset: 1452x577@int16, <sa: chunks,run,subj,targets,task,time_coords,time_indices>, <fa: voxel_indices>, <a: imgaffine,imghdr,imgtype,mapper,voxel_dim,voxel_eldim>\n",
        "stats: mean=1656.47 std=342.034 var=116988 min=352 max=2805\n",
        "\n",
        "Counts of targets in each chunk:\n",
        "  chunks\\targets bottle cat chair face house rest scissors scrambledpix shoe\n",
        "                   ---  ---  ---   ---  ---   ---    ---        ---      ---\n",
        "        0           9    9    9     9    9    49      9          9        9\n",
        "        1           9    9    9     9    9    49      9          9        9\n",
        "        2           9    9    9     9    9    49      9          9        9\n",
        "        3           9    9    9     9    9    49      9          9        9\n",
        "        4           9    9    9     9    9    49      9          9        9\n",
        "        5           9    9    9     9    9    49      9          9        9\n",
        "        6           9    9    9     9    9    49      9          9        9\n",
        "        7           9    9    9     9    9    49      9          9        9\n",
        "        8           9    9    9     9    9    49      9          9        9\n",
        "        9           9    9    9     9    9    49      9          9        9\n",
        "       10           9    9    9     9    9    49      9          9        9\n",
        "       11           9    9    9     9    9    49      9          9        9\n",
        "\n",
        "Summary for targets across chunks\n",
        "    targets  mean std min max #chunks\n",
        "   bottle      9   0   9   9     12\n",
        "     cat       9   0   9   9     12\n",
        "    chair      9   0   9   9     12\n",
        "    face       9   0   9   9     12\n",
        "    house      9   0   9   9     12\n",
        "    rest      49   0   49  49    12\n",
        "  scissors     9   0   9   9     12\n",
        "scrambledpix   9   0   9   9     12\n",
        "    shoe       9   0   9   9     12\n",
        "\n",
        "Summary for chunks across targets\n",
        "  chunks mean  std min max #targets\n",
        "    0    13.4 12.6  9   49     9\n",
        "    1    13.4 12.6  9   49     9\n",
        "    2    13.4 12.6  9   49     9\n",
        "    3    13.4 12.6  9   49     9\n",
        "    4    13.4 12.6  9   49     9\n",
        "    5    13.4 12.6  9   49     9\n",
        "    6    13.4 12.6  9   49     9\n",
        "    7    13.4 12.6  9   49     9\n",
        "    8    13.4 12.6  9   49     9\n",
        "    9    13.4 12.6  9   49     9\n",
        "   10    13.4 12.6  9   49     9\n",
        "   11    13.4 12.6  9   49     9\n",
        "Sequence statistics for 1452 entries from set ['bottle', 'cat', 'chair', 'face', 'house', 'rest', 'scissors', 'scrambledpix', 'shoe']\n",
        "Counter-balance table for orders up to 2:\n",
        "Targets/Order O1                           |  O2                           |\n",
        "   bottle:    96  0  0  0  0  12  0  0  0  |  84  0  0  0  0  24  0  0  0  |\n",
        "     cat:      0 96  0  0  0  12  0  0  0  |   0 84  0  0  0  24  0  0  0  |\n",
        "    chair:     0  0 96  0  0  12  0  0  0  |   0  0 84  0  0  24  0  0  0  |\n",
        "    face:      0  0  0 96  0  12  0  0  0  |   0  0  0 84  0  24  0  0  0  |\n",
        "    house:     0  0  0  0 96  12  0  0  0  |   0  0  0  0 84  24  0  0  0  |\n",
        "    rest:     12 12 12 12 12 491 12 12 12  |  24 24 24 24 24 394 24 24 24  |\n",
        "  scissors:    0  0  0  0  0  12 96  0  0  |   0  0  0  0  0  24 84  0  0  |\n",
        "scrambledpix:  0  0  0  0  0  12  0 96  0  |   0  0  0  0  0  24  0 84  0  |\n",
        "    shoe:      0  0  0  0  0  12  0  0 96  |   0  0  0  0  0  24  0  0 84  |\n",
        "Correlations: min=-0.19 max=0.88 mean=-0.00069 sum(abs)=77\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "In *chap_tutorial_openfmri* you can take a look at an example on how the\n",
      "kind of data preparation described above can be perform in an even more compact\n",
      "way.\n",
      "\n",
      "The next step is to extract the *patterns of activation* from the dataset that\n",
      "we are interested in. But wait! We know that fMRI data is typically\n",
      "contaminated with a lot of noise, or actually *information* that we are not\n",
      "interested in. For example, there are temporal drifts in the data (the signal\n",
      "tends to increase when the scanner is warming up). We also know that the signal\n",
      "is not fully homogeneous throughout the brain.\n",
      "\n",
      "All these artifacts carry a lot of variance that is (hopefully) unrelated\n",
      "to the experiment design, and we should try to remove it to present the\n",
      "classifier with the cleanest signal possible. There are countless ways to\n",
      "pre-process the data to try to achieve this goal. Some keywords are:\n",
      "high/low/band-pass filtering, de-spiking, motion-correcting, intensity\n",
      "normalization, and so on. In this tutorial, we keep it simple. The data we\n",
      "have just loaded is already motion corrected. For every experiment that is\n",
      "longer than a few minutes, as in this case, temporal trend removal, or\n",
      "[detrending](http://pymvpa.org/glossary.html#term-detrending), is crucial."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Basic preprocessing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Detrending"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "PyMVPA provides functionality to remove polynomial trends from the data (other\n",
      "methods are available too), meaning that polynomials are fitted to the time\n",
      "series and only what is not explained by them remains in the dataset. In the\n",
      "case of linear detrending, this means fitting a straight line to the time\n",
      "series of each voxel via linear regression and taking the residuals as the new\n",
      "feature values. Detrending can be seen as a type of data transformation, hence\n",
      "in PyMVPA it is implemented as a mapper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "detrender = PolyDetrendMapper(polyord=1, chunks_attr='chunks')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "What we have just created is a mapper that will perform chunk-wise linear\n",
      "(1st-order polynomial) detrending. Chunk-wise detrending is desirable,\n",
      "since our data stems from 12 different runs, and the assumption of a\n",
      "continuous linear trend across all runs is not appropriate. The mapper is\n",
      "going to use the `chunks` attribute to identify the chunks in the\n",
      "dataset.\n",
      "\n",
      "We have seen that we could simply forward-map our dataset with this mapper.\n",
      "However, if we want to have the mapper present in the datasets processing\n",
      "history breadcrumb track, we can use its\n",
      "[get_mapped()](http://pymvpa.org/generated/mvpa2.datasets.base.Dataset.get_mapped.html#mvpa2-datasets-base-dataset-get-mapped) method. This method will cause\n",
      "the dataset to map a shallow copy of itself with the given mapper, and\n",
      "return it. Let's try:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "detrended_fds = fds.get_mapped(detrender)\n",
      "print detrended_fds.a.mapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Chain: <Flatten>-<StaticFeatureSelection>-<PolyDetrend: ord=1>>\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "`detrended_fds` is easily identifiable as a dataset that has been\n",
      "flattened, sliced, and linearly detrended.\n",
      "\n",
      "Note that detrending doesn't always have to be an explicit step. For example,\n",
      "if you plan on modelling your data with haemodynamic response functions in a\n",
      "general linear model (like it is shown in *chap_tutorial_openfmri* with\n",
      "NiPy), polynomial detrending can be done simultaneously as part of the\n",
      "modeling."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Normalization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "While this will hopefully have solved the problem of temporal drifts in the\n",
      "data, we still have inhomogeneous voxel intensities that can be a problem for\n",
      "some machine learning algorithms. For this tutorial, we are again following a\n",
      "simple approach to address this issue, and perform a feature-wise, chunk-wise\n",
      "Z-scoring of the data.  This has many advantages. First, it is going to scale\n",
      "all features into approximately the same range, and also remove their mean.\n",
      "The latter is quite important, since some classifiers are impaired when working\n",
      "with data having large offsets.  However, we are not going to perform a very\n",
      "simple Z-scoring removing the global mean, but use the *rest* condition samples\n",
      "of the dataset to estimate mean and standard deviation.  Scaling dataset\n",
      "features using these parameters yields a score corresponding to the per\n",
      "time-point voxel intensity difference from the *rest* average.\n",
      "\n",
      "This type of data [normalization](http://pymvpa.org/glossary.html#term-normalization) is, you guessed it, also\n",
      "implemented as a mapper:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zscorer = ZScoreMapper(param_est=('targets', ['rest']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "This mapper configuration implements a [chunk](http://pymvpa.org/glossary.html#term-chunk)-wise (the default)\n",
      "Z-scoring, while estimating mean and standard deviation from samples targets\n",
      "with 'rest' in the respective chunk of data.\n",
      "\n",
      "Remember, all mappers return new datasets that only have copies of what has\n",
      "been modified. However, both detrending and Z-scoring have or will modify the\n",
      "samples themselves. That means that the memory consumption will triple!  We\n",
      "will have the original data, the detrended data, and the Z-scored data, but\n",
      "typically we are only interested in the final processing stage. To reduce the\n",
      "memory footprint, both mappers have siblings that perform the same processing,\n",
      "but without copying the data. For [PolyDetrendMapper](http://pymvpa.org/generated/mvpa2.mappers.detrend.PolyDetrendMapper.html#mvpa2-mappers-detrend-polydetrendmapper)\n",
      "this is [poly_detrend()](http://pymvpa.org/generated/mvpa2.mappers.detrend.poly_detrend.html#mvpa2-mappers-detrend-poly-detrend), and for\n",
      "[ZScoreMapper](http://pymvpa.org/generated/mvpa2.mappers.zscore.ZScoreMapper.html#mvpa2-mappers-zscore-zscoremapper) this is [zscore()](http://pymvpa.org/generated/mvpa2.mappers.zscore.zscore.html#mvpa2-mappers-zscore-zscore).\n",
      "The following call will do the same as the mapper we have created above, but\n",
      "using less memory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zscore(detrended_fds, param_est=('targets', ['rest']))\n",
      "fds = detrended_fds\n",
      "print fds.a.mapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Chain: <Flatten>-<StaticFeatureSelection>-<PolyDetrend: ord=1>-<ZScore>>\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Exercise**\n",
      "\n",
      "\n",
      "\n",
      "Look at the \n",
      "*example_smellit* example. Using the techniques from\n",
      "this example, explore the dataset we have just created and look at the\n",
      "effect of detrending and Z-scoring."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you can use this cell for this exercise\n",
      "fds_orig = vstack(run_dataset, a=0)\n",
      "pl.figure(fig_size=[9,6])\n",
      "pl.subplot(121); plot_samples_distances(fds_orig, sortbyattr='targets')\n",
      "pl.subplot(122); plot_samples_distances(fds, sortbyattr='targets')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'run_dataset' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-35-10d0279446cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# you can use this cell for this exercise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfds_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplot_samples_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfds_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msortbyattr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mplot_samples_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msortbyattr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'run_dataset' is not defined"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "\n",
      "\n",
      "The resulting dataset is now both detrended and normalized. The information\n",
      "is nicely presented in the mapper. From this point on we have no use for\n",
      "the samples of the *rest* category anymore, hence we remove them from the\n",
      "dataset:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fds = fds[fds.sa.targets != 'rest']\n",
      "print fds.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(864, 577)\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Computing \n",
      "*Patterns Of Activation*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "The last preprocessing step is to compute the actual *patterns of activation*.\n",
      "In the original study, Haxby and colleagues performed a GLM-analysis of odd vs.\n",
      "even runs of the data respectively and used the corresponding contrast\n",
      "statistics (stimulus category vs. rest) as classifier input. In this tutorial,\n",
      "we will use a much simpler shortcut and just compute *mean* samples per\n",
      "condition for both odd and even run independently.\n",
      "\n",
      "To achieve this, we first add a new sample attribute to assign a\n",
      "corresponding label to each sample in the dataset that indicates which of\n",
      "both run-types it belongs to:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rnames = {0: 'even', 1: 'odd'}\n",
      "fds.sa['runtype'] = [rnames[c % 2] for c in fds.sa.chunks]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "The rest is trivial. For cases like this -- applying a function (i.e. mean)\n",
      "to a set of groups of samples (all combinations of stimulus category and\n",
      "run-type) -- PyMVPA has [FxMapper](http://pymvpa.org/generated/mvpa2.mappers.fx.FxMapper.html#mvpa2-mappers-fx-fxmapper). it comes with a number\n",
      "of convenience functions. The one we need here is\n",
      "[mean_group_sample()](http://pymvpa.org/generated/mvpa2.mappers.fx.mean_group_sample.html#mvpa2-mappers-fx-mean-group-sample). It takes a list of sample attributes,\n",
      "determines all possible combinations of its unique values, selects dataset\n",
      "samples corresponding to these combinations, and averages them. Finally,\n",
      "since this is also a mapper, a new dataset with mean samples is returned:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "averager = mean_group_sample(['targets', 'runtype'])\n",
      "type(averager)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "mvpa2.mappers.fx.FxMapper"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fds = fds.get_mapped(averager)\n",
      "fds.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "(16, 577)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fds.sa.targets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['bottle' 'cat' 'chair' 'face' 'house' 'scissors' 'scrambledpix' 'shoe'\n",
        " 'bottle' 'cat' 'chair' 'face' 'house' 'scissors' 'scrambledpix' 'shoe']\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fds.sa.chunks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['0+2+4+6+8+10' '0+2+4+6+8+10' '0+2+4+6+8+10' '0+2+4+6+8+10' '0+2+4+6+8+10'\n",
        " '0+2+4+6+8+10' '0+2+4+6+8+10' '0+2+4+6+8+10' '1+3+5+7+9+11' '1+3+5+7+9+11'\n",
        " '1+3+5+7+9+11' '1+3+5+7+9+11' '1+3+5+7+9+11' '1+3+5+7+9+11' '1+3+5+7+9+11'\n",
        " '1+3+5+7+9+11']\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Here we go! We now have a fully-preprocessed dataset: masked, detrended, normalized,\n",
      "with one sample per stimulus condition that is an average for odd and even runs\n",
      "respectively. Now we could do some serious classification, and this will be\n",
      "shown in *chap_tutorial_classifiers*, but there is still an\n",
      "important aspect of mappers we have to look at first."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "There and back again -- a Mapper's tale"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Let's take a look back at the simple datasets from the start of the tutorial\n",
      "part."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Dataset: 5x12@float64, <a: mapper>>\n"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ds.a.mapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<FlattenMapper>\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "A very important feature of mappers is that they allow to reverse a\n",
      "transformation, if that is possible. In case of the simple dataset we can\n",
      "ask the mapper to undo the flattening and to put our samples back into the\n",
      "original 3D shape."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orig_data = ds.a.mapper.reverse(ds.samples)\n",
      "orig_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "(5, 4, 3)"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "In interactive scripting sessions this is would be a relatively bulky command\n",
      "to type, although it might be quite frequently used. To make ones fingers\n",
      "suffer less there is a little shortcut that does exactly the same:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orig_data = ds.O\n",
      "orig_data.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "(5, 4, 3)"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "It is important to realize that reverse-mapping not only works with a single\n",
      "mapper, but also with a [ChainMapper](http://pymvpa.org/generated/mvpa2.mappers.base.ChainMapper.html#mvpa2-mappers-base-chainmapper). Going back to our\n",
      "demo dataset from the beginning we can see how it works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print subds"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Dataset: 5x4@float64, <a: mapper>>\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print subds.a.mapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Chain: <Flatten>-<StaticFeatureSelection>>\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subds.nfeatures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "revtest = np.arange(subds.nfeatures) + 10\n",
      "print revtest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[10 11 12 13]\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rmapped = subds.a.mapper.reverse1(revtest)\n",
      "rmapped.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 50,
       "text": [
        "(4, 3)"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print rmapped"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0 10 11]\n",
        " [ 0  0  0]\n",
        " [ 0  0 12]\n",
        " [ 0 13  0]]\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Reverse mapping of a single sample (one-dimensional feature vector) through the\n",
      "mapper chain created a 4x3 array that corresponds to the dimensions of a sample\n",
      "in our original data space. Moreover, we see that each feature value is\n",
      "precisely placed into the position that corresponds to the features selected\n",
      "in the previous dataset slicing operation.\n",
      "\n",
      "But now let's look at our fMRI dataset again. Here the mapper chain is a little\n",
      "more complex:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print fds.a.mapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<Chain: <Flatten>-<StaticFeatureSelection>-<PolyDetrend: ord=1>-<ZScore>-<Fx: fx=mean>>\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "Initial flattening followed by mask, detrending, Z-scoring and finally\n",
      "averaging. We would reverse mapping do in this case? Let's test:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fds.nfeatures"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "577"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "revtest = np.arange(100, 100 + fds.nfeatures)\n",
      "rmapped = fds.a.mapper.reverse1(revtest)\n",
      "rmapped.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "(40, 64, 64)"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "What happens is exactly what we expect: The initial one-dimensional vector\n",
      "is passed backwards through the mapper chain. Reverting a group-based\n",
      "averaging doesn't make much sense for a single vector, hence it is ignored.\n",
      "Same happens for Z-Scoring and temporal detrending. However, for all\n",
      "remaining mappers the transformations are reverse. First unmasked, and\n",
      "then reshaped into the original dimensionality -- the brain volume.\n",
      "\n",
      "We can check that this is really the case by only reverse-mapping through\n",
      "the first two mappers in the chain and compare the result:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rmapped_partial = fds.a.mapper[:2].reverse1(revtest)\n",
      "(rmapped == rmapped_partial).all()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "In case you are wondering: The [ChainMapper](http://pymvpa.org/generated/mvpa2.mappers.base.ChainMapper.html#mvpa2-mappers-base-chainmapper) behaves\n",
      "like a regular Python list. We have just selected the first two mappers in\n",
      "the list as another [ChainMapper](http://pymvpa.org/generated/mvpa2.mappers.base.ChainMapper.html#mvpa2-mappers-base-chainmapper) and used that one for\n",
      "reverse-mapping."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Back To NIfTI"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "One last interesting aspect in the context of reverse mapping: Whenever it\n",
      "is necessary to export data from PyMVPA, such as results, dataset mappers\n",
      "also play a critical role. For example we can easily export the `revtest`\n",
      "vector into a NIfTI brain volume image. This is possible because the mapper\n",
      "can put it back into 3D space, and because the dataset also stores\n",
      "information about the original source NIfTI image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'imghdr' in fds.a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "PyMVPA offers [map2nifti()](http://pymvpa.org/generated/mvpa2.datasets.mri.map2nifti.html#mvpa2-datasets-mri-map2nifti), a function to combine these\n",
      "two things and convert any vector into the corresponding NIfTI image:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nimg = map2nifti(fds, revtest)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "This image can now be stored as a file (e.g. `nimg.to_filename('mytest.nii.gz')`).\n",
      "In this format it is now compatible with the vast majority of neuroimaging\n",
      "software."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "**Exercise**\n",
      "\n",
      "\n",
      "\n",
      "Save the NIfTI image to some file, and use an MRI viewer to overlay it\n",
      "on top of the anatomical image in the demo dataset. Does it match our\n",
      "original mask image of ventral temporal cortex?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# you can use this cell for this exercise\n",
      "nimg.to_filename('mydata.nii.gz')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- - -\n",
      "\n",
      "\n",
      "There are many more mappers in PyMVPA than we could cover in the tutorial\n",
      "part. Some more will be used in other parts, but even more can be found the\n",
      "[mappers](http://pymvpa.org/generated/mvpa2.mappers.html#mvpa2-mappers) module. Even though they all implement different\n",
      "transformations, they can all be used in the same way, and can all be\n",
      "combined into a chain."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}